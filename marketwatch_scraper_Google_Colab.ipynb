{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "marketwatch_scraper_Google_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw14LlZLsGQM"
      },
      "source": [
        "# Selenium\n",
        "Allow the remote contro of a browser, in this case firefox\n",
        "\n",
        "See the [Manual](https://www.seleniumhq.org/docs/03_webdriver.jsp) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BjPnvG8RMrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf2fee6-364d-4af1-88d8-d9ab6ecc9577"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
            "\u001b[K     |████████████████████████████████| 904 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [67.0 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,426 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,200 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,295 kB]\n",
            "Get:20 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [41.6 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,731 kB]\n",
            "Fetched 9,038 kB in 4s (2,223 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 57 not upgraded.\n",
            "Need to get 91.8 MB of archives.\n",
            "After this operation, 315 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 92.0.4515.159-0ubuntu0.18.04.1 [1,124 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 92.0.4515.159-0ubuntu0.18.04.1 [81.7 MB]\n",
            "30% [2 chromium-browser 27.7 MB/81.7 MB 34%]\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbU12fTkc0le"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "main_path = os.getcwd()\n",
        "download_folder_name = 'marketWatch_Downloads'\n",
        "download_path = main_path+'\\\\'+download_folder_name\n",
        "if os.path.exists(download_path) == True:\n",
        "  for files in os.listdir(download_path):\n",
        "    os.remove(os.path.join(download_path, files))\n",
        "else:\n",
        "  os.mkdir(download_path)\n",
        "\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_experimental_option(\"prefs\",{\"download.default_directory\":download_path,\n",
        "                                             \"download.prompt_for_download\": False,\n",
        "                                             \"download.directory_upgrade\": True,\n",
        "                                             \"safebrowsing.enabled\": True})\n",
        "\n",
        "driver = webdriver.Chrome(executable_path='chromedriver', options=options)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO7bH8uObpwr"
      },
      "source": [
        "##################### Selenium Scraper ###########################\n",
        "def header_market_table_data_crawler(driver): # This function will scrape the table headings and return it to user and wait for desired input to fetch the data\n",
        "# Fetching the header names viz. US EUROPE Asia FX Rates Futures Crypto\n",
        "    market_item_list = driver.find_elements_by_xpath(\"//div[contains(@class,'markets desktop')]/ul/li\")\n",
        "\n",
        "    print(\"Market items in the Market Table are:\\n\")\n",
        "    header_count = 1\n",
        "    for item in range(0, len(market_item_list)):\n",
        "        if item == 7:\n",
        "            # Reason : The market_item_list also consists of market_item_dropdown which is not required.\n",
        "            break\n",
        "        else:\n",
        "            print(str(header_count) + \". \" + market_item_list[item].text)\n",
        "            header_count += 1\n",
        "# Asking for Input and Clicking the Element\n",
        "    choice_header = input(\"\\nChoose Your Preference: \")\n",
        "\n",
        "    if choice_header >= '8' or choice_header <= '0':\n",
        "        print(\"\\nWrong Choice: Refreshing the program..\\n\")\n",
        "        refresh_reason = \"Wrong Choice\"\n",
        "        refresh_page(driver,refresh_reason)\n",
        "    else:\n",
        "        print(\"\\nYou chose: \" + (market_item_list[int(choice_header)-1]).text)\n",
        "        final_item_choice_header = market_item_list[int(choice_header)-1]\n",
        "        driver.execute_script('arguments[0].click()', final_item_choice_header)\n",
        "        # final_item_choice_header.click()\n",
        "        time.sleep(2)\n",
        "        click_table_data_symbol(driver)\n",
        "#     final_item_choice_header = market_item_list[5]\n",
        "#     final_item_choice_header.click()\n",
        "#     time.sleep(2)\n",
        "#     click_table_data_symbol(driver)\n",
        "\n",
        "def click_table_data_symbol(driver): # This function will fetch the table data and display the symbol to the user and wait for the desired input to fetch the data\n",
        "# Scraping the market table symbol names\n",
        "\n",
        "    symbol_count = 1\n",
        "    market_data_symbol_list = driver.find_elements_by_xpath(\"//div[contains(@class,'markets__table')]/table/tbody/tr/td[2]\")\n",
        "    print(\"\\nSymbol list:\\n\")\n",
        "    for market_item in market_data_symbol_list:\n",
        "        print(str(symbol_count) + \". \" + market_item.text)\n",
        "        symbol_count += 1\n",
        "# Asking for user input to Fetch the Element\n",
        "    choice_symbol = input(\"\\nChoose Your Preference: \")\n",
        "    if choice_symbol >= '7' or choice_symbol <= '0':\n",
        "        refresh_page(driver,refresh_reason=\"Wrong Choice\")\n",
        "        print(\"\\nWrong Choice... Restarting from the Begining\\n\")\n",
        "    else:\n",
        "        final_choice_symbol = market_data_symbol_list[int(choice_symbol)-1]\n",
        "        final_choice_symbol.click()\n",
        "        subnavigation_choice(driver)\n",
        "    # final_choice_symbol = market_data_symbol_list[2]\n",
        "    # final_choice_symbol.click()\n",
        "    # overview_contracts_latest_scraper(driver)\n",
        "    # subnavigation_choice(driver)\n",
        "\n",
        "def refresh_page(driver,refresh_reason):\n",
        "    driver.refresh()\n",
        "    if refresh_reason == \"Wrong Choice\":\n",
        "        header_market_table_data_crawler(driver)\n",
        "\n",
        "\n",
        "\n",
        "################################################################################################################\n",
        "##################################### Scraping Item Details#####################################################\n",
        "\n",
        "\n",
        "\n",
        "def subnavigation_choice(driver): # This function gives User to choose his preferred choice of navigation he wants to scrape\n",
        "\n",
        "    # Fetching the Sub Navigation header Names\n",
        "\n",
        "    subnavigation_list = driver.find_elements_by_xpath(\"//div[contains(@class,'subnav')]/li\")\n",
        "\n",
        "    print(\"\\nSub-Navigation Pane::::\\n\")\n",
        "    # navigation_count = 1\n",
        "    # for item in range(0,len(subnavigation_list)):\n",
        "    #     print(str(navigation_count) + \". \" + subnavigation_list[item].text)\n",
        "    #     navigation_count += 1\n",
        "    print(\"1.Overview\")\n",
        "    print(\"2.Charts\")\n",
        "    print(\"3.Historics\")\n",
        "    # Asking for User's Choice and forwarding to the desired function\n",
        "    print(\"\\nDon't Type no.2 as it is not done yet\\n\")\n",
        "    subnav_choice = input(\"\\nChoose Your Preferred option: \")\n",
        "\n",
        "    if subnav_choice >= '4' or subnav_choice <= '0':# First_Try\n",
        "        print(\"\\nOops! Wrong Choice. Refreshing program\\n\")\n",
        "        refresh_page(driver, refresh_reason=\"Wrong Choice\")\n",
        "\n",
        "    else:\n",
        "        if subnav_choice == '1':\n",
        "            print(\"\\nScraping \" + (subnavigation_list[int(subnav_choice) - 1]).text+ \"\\n\")\n",
        "            overview_scraper(driver)\n",
        "        if subnav_choice == '2':\n",
        "            print(\"\\nCHARTS ARE NOT WORKING!!! RESTARTING PROGRAM\" + \"\\n\")\n",
        "            refresh_page(driver,refresh_reason=\"Wrong Choice\")\n",
        "        if subnav_choice == '3':\n",
        "            print(\"\\nScraping \" + (subnavigation_list[int(subnav_choice) - 1]).text+ \"\\n\")\n",
        "            historical_Quotes_scraper(driver)\n",
        "    # charts_scraper(driver)\n",
        "    # historical_Quotes_scraper(driver)\n",
        "    # overview_contracts_latest_scraper(driver)\n",
        "\n",
        "\n",
        "\n",
        "################################################################################################################\n",
        "##################################### Scraping Overview ########################################################\n",
        "\n",
        "\n",
        "\n",
        "def overview_scraper(driver):# This function will click the overview button\n",
        "    overview_Xpath = driver.find_element_by_xpath(\"//div[contains(@class,'subnav')]/li[1]\")\n",
        "    overview_Xpath.location_once_scrolled_into_view\n",
        "    driver.execute_script(\"arguments[0].click();\", overview_Xpath)# Click the overview Button\n",
        "    overview_keyData_scraper(driver)\n",
        "    overview_performance_scraper(driver)\n",
        "    overview_top_Performer_scraper(driver)\n",
        "    overview_bottom_Performer_scraper(driver)\n",
        "    overview_contracts_latest_scraper(driver)\n",
        "\n",
        "\n",
        "def overview_keyData_scraper(driver):# Scraping the Primary Details viz. Key Data, Performance, Top Performer\n",
        "\n",
        "    open_Data = driver.find_element_by_xpath(\"//div[contains(@class,'elements left')]//ul/li[1]/span[contains(@class,'primary')]\").text\n",
        "    dayRange_Data = driver.find_element_by_xpath(\"//div[contains(@class,'elements left')]//ul/li[2]/span[contains(@class,'primary')]\").text\n",
        "    week52Range_Data = driver.find_element_by_xpath(\"//div[contains(@class,'elements left')]//ul/li[3]/span[contains(@class,'primary')]\").text\n",
        "    keydata_handling(open_Data,dayRange_Data,week52Range_Data)\n",
        "\n",
        "\n",
        "def overview_performance_scraper(driver): # Scraping Performance Data from Overview Tab\n",
        "\n",
        "    performance_Xpath = driver.find_element_by_xpath(\"//div[contains(@class,'performance')]\")\n",
        "    performance_Xpath.location_once_scrolled_into_view\n",
        "    performance_table_row_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'performance')]//table//tr\")\n",
        "    performance_table_row_data_list=[]\n",
        "    for table_row in range(1,len(performance_table_row_Xpath)):\n",
        "        performance_table_row_data_list.append(performance_table_row_Xpath[table_row-1].text)\n",
        "    overview_performance_data_handling(performance_table_row_data_list)\n",
        "\n",
        "\n",
        "def overview_top_Performer_scraper(driver):# Scraping Top Performer from Overview button\n",
        "    # Check if top performer Xpath is present\n",
        "    try:\n",
        "        driver.find_element_by_xpath(\"//div[contains(@class,'ByIndexGainers')]/header/h2\")\n",
        "    except:\n",
        "        print(\"Top Performer not found. Checking for Bottom Performer next\")\n",
        "        return\n",
        "\n",
        "    top_performer_Xpath = driver.find_element_by_xpath(\"//div[contains(@class,'ByIndexGainers')]/header/h2\")\n",
        "    top_performer_Xpath.location_once_scrolled_into_view\n",
        "    top_performer_table_header_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'ByIndexGainers')]/table/thead//th\")\n",
        "    top_performer_name_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'ByIndexGainers')]/table/tbody//tr/td[1]\")\n",
        "    top_performer_last_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'ByIndexGainers')]/table/tbody//tr/td[2]\")\n",
        "    top_performer_change_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'ByIndexGainers')]/table/tbody//tr/td[3]\")\n",
        "    top_performer_change_percent_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'ByIndexGainers')]/table/tbody//tr/td[4]\")\n",
        "\n",
        "    top_performer_table_header_data_list =[]\n",
        "    top_performer_name_list = []\n",
        "    top_performer_last_list = []\n",
        "    top_performer_change_list = []\n",
        "    top_performer_change_percent_list = []\n",
        "\n",
        "# Scraping each row data separately for better data handling\n",
        "\n",
        "    for table_header in range(0,len(top_performer_table_header_Xpath)): # Scraping Header Names from Top Performers Table\n",
        "        top_performer_table_header_data_list.append(top_performer_table_header_Xpath[table_header].text)\n",
        "\n",
        "\n",
        "    for table_name in range(0,len(top_performer_name_Xpath)): # Scraping Top Performer Companies From Top Performers Table\n",
        "        top_performer_name_list.append(top_performer_name_Xpath[table_name].text)\n",
        "\n",
        "\n",
        "    for table_last in range(0,len(top_performer_last_Xpath)): # Scraping Last Column Data From Top Performers Table\n",
        "        top_performer_last_list.append(top_performer_last_Xpath[table_last].text)\n",
        "\n",
        "\n",
        "    for table_change in range(0,len(top_performer_change_Xpath)): # Scraping Change Data From Top Performers Table\n",
        "        top_performer_change_list.append(top_performer_change_Xpath[table_change].text)\n",
        "\n",
        "\n",
        "    for table_change_percent in range(0,len(top_performer_change_percent_Xpath)): # Scraping Change percentage Data From Top Performers Table\n",
        "        top_performer_change_percent_list.append(top_performer_change_percent_Xpath[table_change_percent].text)\n",
        "\n",
        "    overview_performer_data_handling(top_performer_table_header_data_list,\n",
        "                                         top_performer_name_list, top_performer_last_list,\n",
        "                                         top_performer_change_list,top_performer_change_percent_list,reason = \"Top Performer\")\n",
        "\n",
        "\n",
        "def overview_bottom_Performer_scraper(driver):\n",
        "    # Check if top performer Xpath is present\n",
        "    try:\n",
        "        driver.find_element_by_xpath(\"//div[contains(@class,'ByIndexDecliners')]/header/h2\")\n",
        "    except:\n",
        "        print(\"Bottom Performer not found.\")\n",
        "        return\n",
        "\n",
        "    bottom_performer_Xpath = driver.find_element_by_xpath(\"//div[contains(@class,'ByIndexDecliners')]/header/h2\")\n",
        "    bottom_performer_Xpath.location_once_scrolled_into_view\n",
        "    bottom_performer_table_header_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'ByIndexDecliners')]/table/thead//th\")\n",
        "    bottom_performer_name_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'ByIndexDecliners')]/table/tbody//tr/td[1]\")\n",
        "    bottom_performer_last_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'ByIndexDecliners')]/table/tbody//tr/td[2]\")\n",
        "    bottom_performer_change_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'ByIndexDecliners')]/table/tbody//tr/td[3]\")\n",
        "    bottom_performer_change_percent_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'ByIndexDecliners')]/table/tbody//tr/td[4]\")\n",
        "\n",
        "    bottom_performer_table_header_data_list = []\n",
        "    bottom_performer_name_list = []\n",
        "    bottom_performer_last_list = []\n",
        "    bottom_performer_change_list = []\n",
        "    bottom_performer_change_percent_list = []\n",
        "\n",
        "    # Scraping each row data separately for better data handling\n",
        "    for table_header in range(0, len(bottom_performer_table_header_Xpath)):  # Scraping Header Names from Bottom Performers Table\n",
        "        bottom_performer_table_header_data_list.append(bottom_performer_table_header_Xpath[table_header].text)\n",
        "\n",
        "    for table_name in range(0, len(bottom_performer_name_Xpath)):  # Scraping bottom Performer Companies From Bottom Performers Table\n",
        "        bottom_performer_name_list.append(bottom_performer_name_Xpath[table_name].text)\n",
        "\n",
        "    for table_last in range(0,len(bottom_performer_last_Xpath)):  # Scraping Last Column Data From Bottom Performers Table\n",
        "        bottom_performer_last_list.append(bottom_performer_last_Xpath[table_last].text)\n",
        "\n",
        "    for table_change in range(0,len(bottom_performer_change_Xpath)):  # Scraping Change Data From Bottom Performers Table\n",
        "        bottom_performer_change_list.append(bottom_performer_change_Xpath[table_change].text)\n",
        "\n",
        "    for table_change_percent in range(0, len(bottom_performer_change_percent_Xpath)):  # Scraping Change percentage Data From Bottom Performers Table\n",
        "        bottom_performer_change_percent_list.append(bottom_performer_change_percent_Xpath[table_change_percent].text)\n",
        "\n",
        "    overview_performer_data_handling(bottom_performer_table_header_data_list, bottom_performer_name_list,\n",
        "                                         bottom_performer_last_list, bottom_performer_change_list,\n",
        "                                         bottom_performer_change_percent_list, reason=\"Bottom Performer\")\n",
        "\n",
        "\n",
        "\n",
        "def overview_contracts_latest_scraper(driver): # This function only works in futures\n",
        "    # Check if Contracts found\n",
        "    # breakpoint()\n",
        "    try:\n",
        "        driver.find_element_by_xpath(\"//div[contains(@class,'FuturesContracts')]\")\n",
        "        print(\"Recent Contracts Found!!\")\n",
        "    except:\n",
        "        print(\"No Recent Contracts Found!!\")\n",
        "        driver.close()\n",
        "        sys.exit()\n",
        "\n",
        "    body = driver.find_element_by_css_selector('body')\n",
        "    body.send_keys(Keys.PAGE_DOWN)\n",
        "    recent_contracts_Xpath = driver.find_element_by_xpath(\"//div[contains(@class,'FuturesContracts')]\")\n",
        "    recent_contracts_Xpath.location_once_scrolled_into_view\n",
        "    recent_contracts_table_header_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'FuturesContracts')]/table/thead/tr/th\")\n",
        "    recent_contracts_table_contracts_name_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'FuturesContracts')]/table/tbody/tr/td[1]\")\n",
        "    recent_contracts_table_contracts_last_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'FuturesContracts')]/table/tbody/tr/td[2]\")\n",
        "    recent_contracts_table_contracts_change_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'FuturesContracts')]/table/tbody/tr/td[3]\")\n",
        "    recent_contracts_table_contracts_open_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'FuturesContracts')]/table/tbody/tr/td[4]\")\n",
        "    recent_contracts_table_contracts_high_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'FuturesContracts')]/table/tbody/tr/td[5]\")\n",
        "    recent_contracts_table_contracts_low_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'FuturesContracts')]/table/tbody/tr/td[6]\")\n",
        "    recent_contracts_table_contracts_date_Xpath = driver.find_elements_by_xpath(\"//div[contains(@class,'FuturesContracts')]/table/tbody/tr/td[7]\")\n",
        "\n",
        "    recent_contracts_table_header_list =[]\n",
        "    recent_contracts_table_contracts_name_list = []\n",
        "    recent_contracts_table_contracts_last_list = []\n",
        "    recent_contracts_table_contracts_change_list = []\n",
        "    recent_contracts_table_contracts_open_list = []\n",
        "    recent_contracts_table_contracts_high_list = []\n",
        "    recent_contracts_table_contracts_low_list = []\n",
        "    recent_contracts_table_contracts_date_list = []\n",
        "\n",
        "    for header_data in range(0,len(recent_contracts_table_header_Xpath)):\n",
        "        if header_data == 0:\n",
        "            recent_contracts_table_header_list.append('NAME')\n",
        "        else:\n",
        "            recent_contracts_table_header_list.append(recent_contracts_table_header_Xpath[header_data].text)\n",
        "    # print(recent_contracts_table_header_list)\n",
        "\n",
        "    for name_data in range(0,len(recent_contracts_table_contracts_name_Xpath)):\n",
        "        recent_contracts_table_contracts_name_list.append(recent_contracts_table_contracts_name_Xpath[name_data].text)\n",
        "    # print(recent_contracts_table_contracts_name_list)\n",
        "\n",
        "    for last_data in range(0,len(recent_contracts_table_contracts_last_Xpath)):\n",
        "        recent_contracts_table_contracts_last_list.append(recent_contracts_table_contracts_last_Xpath[last_data].text)\n",
        "    # print(recent_contracts_table_contracts_last_list)\n",
        "\n",
        "    for change_data in range(0,len(recent_contracts_table_contracts_change_Xpath)):\n",
        "        recent_contracts_table_contracts_change_list.append(recent_contracts_table_contracts_change_Xpath[change_data].text)\n",
        "    # print(recent_contracts_table_contracts_change_list)\n",
        "\n",
        "    for open_data in range(0,len(recent_contracts_table_contracts_open_Xpath)):\n",
        "        recent_contracts_table_contracts_open_list.append(recent_contracts_table_contracts_open_Xpath[open_data].text)\n",
        "    # print(recent_contracts_table_contracts_open_list)\n",
        "\n",
        "    for high_data in range(0,len(recent_contracts_table_contracts_high_Xpath)):\n",
        "        recent_contracts_table_contracts_high_list.append(recent_contracts_table_contracts_high_Xpath[high_data].text)\n",
        "    # print(recent_contracts_table_contracts_high_list)\n",
        "\n",
        "    for low_data in range(0,len(recent_contracts_table_contracts_low_Xpath)):\n",
        "        recent_contracts_table_contracts_low_list.append(recent_contracts_table_contracts_low_Xpath[low_data].text)\n",
        "    # print(recent_contracts_table_contracts_low_list)\n",
        "\n",
        "    for date_data in range(0,len(recent_contracts_table_contracts_date_Xpath)):\n",
        "        recent_contracts_table_contracts_date_list.append(recent_contracts_table_contracts_date_Xpath[date_data].text)\n",
        "    # print(recent_contracts_table_contracts_date_list)\n",
        "\n",
        "    future_contract_data_handling(recent_contracts_table_header_list,recent_contracts_table_contracts_name_list,recent_contracts_table_contracts_last_list,\n",
        "                                      recent_contracts_table_contracts_change_list,recent_contracts_table_contracts_open_list,\n",
        "                                      recent_contracts_table_contracts_high_list,recent_contracts_table_contracts_low_list,recent_contracts_table_contracts_date_list)\n",
        "\n",
        "\n",
        "\n",
        "################################################################################################################\n",
        "##################################### Scraping Charts Details#####################################################\n",
        "\n",
        "\n",
        "\n",
        "def charts_scraper(driver):\n",
        "    charts_xpath = driver.find_element_by_xpath(\"//div[contains(@class,'subnav')]/li[2]\")\n",
        "    print(\"Not available Right Now\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################################################################\n",
        "##################################### Scraping Historical Quotes Details#####################################################\n",
        "\n",
        "\n",
        "\n",
        "def historical_Quotes_scraper(driver):\n",
        "\n",
        "    historical_Xpath = driver.find_element_by_xpath(\"//div[contains(@class,'subnav')]/li[3]/a\")\n",
        "\n",
        "    body = driver.find_element_by_css_selector('body')\n",
        "    body.send_keys(Keys.PAGE_DOWN)\n",
        "\n",
        "    driver.execute_script('arguments[0].click()', historical_Xpath)\n",
        "\n",
        "    # Show Result Frequency\n",
        "    # breakpoint()\n",
        "    time.sleep(2)\n",
        "    result_frequency_list = driver.find_elements_by_xpath(\"//div[contains(@class,'element__options')]/ul/li\")\n",
        "\n",
        "    body = driver.find_element_by_css_selector('body')\n",
        "    body.send_keys(Keys.PAGE_DOWN)\n",
        "\n",
        "    print(\"\\nResult Frequency: \\n\")\n",
        "\n",
        "    freq_count = 1\n",
        "\n",
        "    for item in range(0, len(result_frequency_list)):\n",
        "        print(str(freq_count) + \". \" + result_frequency_list[item].text)\n",
        "        freq_count += 1\n",
        "\n",
        "    # Asking for Input and Clicking the Element\n",
        "    choice_result = input(\"\\nChoose Your Preference: \")\n",
        "\n",
        "    if choice_result >= '4' or choice_result <= '0':\n",
        "        print(\"\\nWrong Choice: Refreshing the program..\\n\")\n",
        "        refresh_page(driver,refresh_reason = \"Wrong Choice\")\n",
        "    else:\n",
        "        print(\"\\nYou chose: \" + (result_frequency_list[int(choice_result)-1]).text)\n",
        "        final_item_choice_result = result_frequency_list[int(choice_result)-1]\n",
        "        driver.execute_script('arguments[0].click()', final_item_choice_result)\n",
        "        time.sleep(2)\n",
        "        Download_CSV(driver,choice_result)\n",
        "\n",
        "    # final_item_choice_result = result_frequency_list[0]# Daily\n",
        "    # # final_item_choice_result = result_frequency_list[1]  # Weekly\n",
        "    # # final_item_choice_result = result_frequency_list[2]  # Monthly\n",
        "    # driver.execute_script('arguments[0].click()', final_item_choice_result)\n",
        "    # Download_CSV(driver)\n",
        "\n",
        "def Download_CSV(driver,choice_result):# Downloading CSV\n",
        "    download_Xpath = driver.find_element_by_xpath(\"(//div[contains(@class,'tabPanes')]/div[\"+str(choice_result)+\"]//a)[1]\")\n",
        "    driver.execute_script('arguments[0].click()', download_Xpath)\n",
        "    main_path = os.getcwd()\n",
        "    download_folder_name = 'marketWatch_Downloads'\n",
        "    download_path = main_path + '\\\\' + download_folder_name\n",
        "    if os.path.exists(download_path) == True:\n",
        "        print(\"\\nDownloading CSV\\n\")\n",
        "        while len(os.listdir(download_path)) == 0:\n",
        "            time.sleep(1)\n",
        "            if len(os.listdir(download_path)) > 0:\n",
        "                break\n",
        "    historical_quotes_data_handling()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OIYFqZJlShz"
      },
      "source": [
        "\n",
        "################################################ Data Handling ################################\n",
        "\n",
        "\n",
        "def keydata_handling(open_Data,dayRange_Data,week52Range_Data): # Key Data Conversion to Dataframe\n",
        "    keydata_df = pd.DataFrame(columns=['Open', 'Day_Range','52_Weeks_Range'])\n",
        "    keydata_df.loc[0] = [open_Data,dayRange_Data,week52Range_Data]\n",
        "    print(\"Key Data:\\n\")\n",
        "    print(keydata_df)\n",
        "\n",
        "\n",
        "def overview_performance_data_handling(performance_table_row_data_list):\n",
        "    preprocessed_list = []\n",
        "    for items in performance_table_row_data_list:\n",
        "        preprocessed_list += (items.splitlines())\n",
        "    row_data = []\n",
        "    column_data = []\n",
        "    for item in range(0, len(preprocessed_list)):\n",
        "        if item % 2 == 1:\n",
        "            row_data.append(preprocessed_list[item])\n",
        "        else:\n",
        "            column_data.append(preprocessed_list[item])\n",
        "    performance_df = pd.DataFrame(columns=column_data)\n",
        "    data_to_append = row_data\n",
        "    performance_df_length = len(performance_df)\n",
        "    performance_df.loc[performance_df_length] = data_to_append\n",
        "    print(\"\\nPerformance Data:\\n\")\n",
        "    print(performance_df)\n",
        "\n",
        "def overview_performer_data_handling(performer_table_header_data_list,performer_name_list,\n",
        "                                     performer_last_list, performer_change_list,performer_change_percent_list,reason):\n",
        "    top_performer_df = ''\n",
        "    bottom_performer_df = ''\n",
        "    if reason == \"Top Performer\":\n",
        "        top_performer_df = pd.DataFrame(list(zip(performer_name_list, performer_last_list, performer_change_list,\n",
        "                                                 performer_change_percent_list)), columns=performer_table_header_data_list)\n",
        "        print(\"\\nTop Performer:\\n\")\n",
        "        print(top_performer_df)\n",
        "\n",
        "    if reason == \"Bottom Performer\":\n",
        "        bottom_performer_df = pd.DataFrame(list(zip(performer_name_list, performer_last_list, performer_change_list,\n",
        "                                                 performer_change_percent_list)), columns=performer_table_header_data_list)\n",
        "        print(\"\\nBottom Performer:\\n\")\n",
        "        print(bottom_performer_df)\n",
        "\n",
        "def historical_quotes_data_handling():\n",
        "    main_path = os.getcwd()\n",
        "    download_folder_name = 'marketWatch_Downloads'\n",
        "    download_path = main_path + '\\\\' + download_folder_name\n",
        "    download_list = os.listdir(download_path)\n",
        "    csv_file_path = ''\n",
        "    for item in download_list:\n",
        "        if '.csv' in item:\n",
        "            print(\"\\nCSV File found!.Converting to dataframe\\n\")\n",
        "            csv_file_path = str(os.path.join(download_path, item))\n",
        "    historical_quotes_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "    print(historical_quotes_df)\n",
        "    print('Plotting the data')\n",
        "    try:  # For row data with comma and decimal point\n",
        "        historical_quotes_df['Date'] = pd.to_datetime(historical_quotes_df['Date'])\n",
        "        historical_quotes_df['Open'] = historical_quotes_df['Open'].str.replace(',', '').astype(float)\n",
        "        historical_quotes_df['High'] = historical_quotes_df['High'].str.replace(',', '').astype(float)\n",
        "        historical_quotes_df['Low'] = historical_quotes_df['Low'].str.replace(',', '').astype(float)\n",
        "        historical_quotes_df['Close'] = historical_quotes_df['Close'].str.replace(',', '').astype(float)\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    try:  # For row data with decimal point\n",
        "        historical_quotes_df['Date'] = pd.to_datetime(historical_quotes_df['Date'])\n",
        "        historical_quotes_df['Open'] = historical_quotes_df['Open'].astype(float)\n",
        "        historical_quotes_df['High'] = historical_quotes_df['High'].astype(float)\n",
        "        historical_quotes_df['Low'] = historical_quotes_df['Low'].astype(float)\n",
        "        historical_quotes_df['Close'] = historical_quotes_df['Close'].astype(float)\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    try:  # For row data with percentage and decimal point\n",
        "\n",
        "        historical_quotes_df['Date'] = pd.to_datetime(historical_quotes_df['Date'])\n",
        "        historical_quotes_df['Open'] = historical_quotes_df['Open'].str.replace('%', '').astype(float)\n",
        "        historical_quotes_df['High'] = historical_quotes_df['High'].str.replace('%', '').astype(float)\n",
        "        historical_quotes_df['Low'] = historical_quotes_df['Low'].str.replace('%', '').astype(float)\n",
        "        historical_quotes_df['Close'] = historical_quotes_df['Close'].str.replace('%', '').astype(float)\n",
        "        print(\"All the values except Date are in percentage. For plotting needed to remove that\")\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    historical_quotes_df[['Date', 'Open', 'High', 'Low', 'Close']].plot(x=\"Date\", kind=\"bar\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def future_contract_data_handling(recent_contracts_table_header_list,recent_contracts_table_contracts_name_list,recent_contracts_table_contracts_last_list,\n",
        "                                      recent_contracts_table_contracts_change_list,recent_contracts_table_contracts_open_list,\n",
        "                                      recent_contracts_table_contracts_high_list,recent_contracts_table_contracts_low_list,recent_contracts_table_contracts_date_list):\n",
        "    recent_contracts_df = ''\n",
        "\n",
        "    recent_contracts_df = pd.DataFrame(list(zip(recent_contracts_table_contracts_name_list, recent_contracts_table_contracts_last_list,recent_contracts_table_contracts_change_list,\n",
        "                                                recent_contracts_table_contracts_open_list,recent_contracts_table_contracts_high_list,recent_contracts_table_contracts_low_list,\n",
        "                                                recent_contracts_table_contracts_date_list)), columns=recent_contracts_table_header_list)\n",
        "\n",
        "    print(recent_contracts_df)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZpsItjmcU1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f6d8c043-2a22-47c5-d38a-dc7acd80be2f"
      },
      "source": [
        "driver.get(\"https://www.marketwatch.com/\")\n",
        "header_market_table_data_crawler(driver)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Market items in the Market Table are:\n",
            "\n",
            "1. US\n",
            "2. Europe\n",
            "3. Asia\n",
            "4. FX\n",
            "5. Rates\n",
            "6. Futures\n",
            "7. Crypto\n",
            "\n",
            "Choose Your Preference: 1\n",
            "\n",
            "You chose: US\n",
            "\n",
            "Symbol list:\n",
            "\n",
            "1. Dow\n",
            "2. S&P 500\n",
            "3. Nasdaq\n",
            "4. GlobalDow\n",
            "5. Gold\n",
            "6. Oil\n",
            "\n",
            "Choose Your Preference: 2\n",
            "\n",
            "Sub-Navigation Pane::::\n",
            "\n",
            "1.Overview\n",
            "2.Charts\n",
            "3.Historics\n",
            "\n",
            "Don't Type no.2 as it is not done yet\n",
            "\n",
            "\n",
            "Choose Your Preferred option: 1\n",
            "\n",
            "Scraping \n",
            "\n",
            "Key Data:\n",
            "\n",
            "       Open            Day_Range       52_Weeks_Range\n",
            "0  4,529.75  4,515.80 - 4,531.39  3,209.45 - 4,537.36\n",
            "\n",
            "Performance Data:\n",
            "\n",
            "   5 Day 1 Month 3 Month     YTD\n",
            "0  0.83%   2.26%   7.65%  20.43%\n",
            "\n",
            "Top Performer:\n",
            "\n",
            "                            NAME     LAST   CHG  CHG %\n",
            "0                      APA Corp.   $19.51  0.85  4.56%\n",
            "1  Walgreens Boots Alliance Inc.   $50.61  1.98  4.07%\n",
            "2        Discovery Inc. Series A   $28.86  1.00  3.61%\n",
            "3        Discovery Inc. Series C   $27.63  0.90  3.37%\n",
            "4            ViacomCBS Inc. Cl B   $41.52  1.29  3.19%\n",
            "5       Willis Towers Watson PLC  $221.33  5.60  2.60%\n",
            "6     Occidental Petroleum Corp.   $25.88  0.63  2.50%\n",
            "7        Lumen Technologies Inc.   $12.25  0.29  2.42%\n",
            "8      Interpublic Group of Cos.   $37.09  0.82  2.25%\n",
            "9   American Airlines Group Inc.   $19.93  0.42  2.17%\n",
            "\n",
            "Bottom Performer:\n",
            "\n",
            "                                  NAME       LAST     CHG   CHG %\n",
            "0                    Wells Fargo & Co.     $45.73   -2.68  -5.54%\n",
            "1              NXP Semiconductors N.V.    $215.60  -12.04  -5.29%\n",
            "2               Under Armour Inc. Cl A     $23.04   -1.08  -4.48%\n",
            "3                 Kansas City Southern    $281.53  -12.03  -4.10%\n",
            "4               Under Armour Inc. Cl C     $19.99   -0.85  -4.08%\n",
            "5  Fortune Brands Home & Security Inc.     $97.43   -3.35  -3.32%\n",
            "6                        Tapestry Inc.     $40.06   -1.20  -2.90%\n",
            "7                          Nucor Corp.    $117.69   -3.36  -2.77%\n",
            "8    J.B. Hunt Transport Services Inc.    $177.76   -4.95  -2.71%\n",
            "9    Mettler-Toledo International Inc.  $1,548.95  -39.78  -2.50%\n",
            "No Recent Contracts Found!!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JshOitG8l02Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}